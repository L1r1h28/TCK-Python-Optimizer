#!/usr/bin/env python3
"""
TCK å„ªåŒ–å ±å‘Šç”Ÿæˆå™¨ (å›ºå®šç‰ˆæœ¬)
============================

å°ˆæ³¨æ–¼é€šç”¨ç¨‹å¼æ¨¡å¼åˆ†æï¼Œç”Ÿæˆé »ç‡æ’åºçš„å„ªåŒ–æ¸…å–®ã€‚

Author: TurboCode Kit (TCK)
Version: 2.0
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List


class OptimizationReportGenerator:
    """å„ªåŒ–å ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "../tck_core/analysis_results"):
        """åˆå§‹åŒ–å ±å‘Šç”Ÿæˆå™¨"""
        self.output_dir = Path(output_dir)
        self.frequency_data = None
        self.complexity_data = None
        
    def load_analysis_data(self) -> bool:
        """è¼‰å…¥åˆ†ææ•¸æ“š"""
        try:
            # è¼‰å…¥é »ç‡åˆ†æçµæœ
            frequency_path = self.output_dir / "frequency_analysis.json"
            if frequency_path.exists():
                with open(frequency_path, 'r', encoding='utf-8') as f:
                    self.frequency_data = json.load(f)
                print("âœ… å·²è¼‰å…¥é »ç‡åˆ†æçµæœ")
            
            # è¼‰å…¥è¤‡é›œåº¦åˆ†æçµæœï¼ˆåªè®€å–æ‘˜è¦éƒ¨åˆ†ï¼‰
            complexity_path = self.output_dir / "complexity_analysis.json"
            if complexity_path.exists() and complexity_path.stat().st_size < 50 * 1024 * 1024:  # å°æ–¼50MB
                with open(complexity_path, 'r', encoding='utf-8') as f:
                    self.complexity_data = json.load(f)
                print("âœ… å·²è¼‰å…¥è¤‡é›œåº¦åˆ†æçµæœ")
            else:
                print("âš ï¸ è¤‡é›œåº¦åˆ†ææª”æ¡ˆéå¤§ï¼Œè·³éè¼‰å…¥")
            
            return self.frequency_data is not None
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥åˆ†ææ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def analyze_code_patterns(self) -> List[Dict]:
        """åˆ†æé€šç”¨ç¨‹å¼æ¨¡å¼ä¸¦æŒ‰é »ç‡æ’åº"""
        if not self.frequency_data:
            return []
        
        patterns = []
        
        # ç²å–å‡½æ•¸èª¿ç”¨æ•¸æ“š
        function_calls = self.frequency_data.get("top_function_calls", {})
        
        # 1. LIST_LOOKUP æ¨¡å¼åˆ†æ - ç·šæ€§æŸ¥æ‰¾æ“ä½œ
        list_operations = {
            "index": function_calls.get("index", 0),
            "count": function_calls.get("count", 0), 
            "remove": function_calls.get("remove", 0),
        }
        list_total = sum(list_operations.values())
        
        if list_total > 5:
            patterns.append({
                "pattern": "LIST_LOOKUP",
                "name": "æ¸…å–®ç·šæ€§æŸ¥æ‰¾æ“ä½œ",
                "frequency": list_total,
                "priority_score": list_total * 10,  # é«˜æ¬Šé‡
                "current_complexity": "O(n)",
                "target_complexity": "O(1)", 
                "description": f"ç™¼ç¾ {list_total} æ¬¡æ¸…å–®ç·šæ€§æŸ¥æ‰¾æ“ä½œ (index: {list_operations['index']}, count: {list_operations['count']}, remove: {list_operations['remove']})",
                "suggestions": [
                    "ä½¿ç”¨ set æˆ– dict é€²è¡Œ O(1) æŸ¥æ‰¾",
                    "å»ºç«‹æŸ¥æ‰¾ç´¢å¼•æ˜ å°„",
                    "ä½¿ç”¨ collections.Counter é€²è¡Œè¨ˆæ•¸æ“ä½œ"
                ],
                "blueprint": "lookup_accelerator.md",
                "example_code": """
# âŒ O(n) ç·šæ€§æŸ¥æ‰¾
if item in my_list:  
    process(item)

# âœ… O(1) é›†åˆæŸ¥æ‰¾
lookup_set = set(my_list)
if item in lookup_set:
    process(item)
"""
            })
        
        # 2. PYTHON_FOR_LOOP æ¨¡å¼åˆ†æ - å¯å‘é‡åŒ–çš„è¿´åœˆ
        loop_count = self.frequency_data.get("loop_distribution", {}).get("For", 0)
        range_calls = function_calls.get("range", 0)
        
        if loop_count > 20:
            patterns.append({
                "pattern": "PYTHON_FOR_LOOP",
                "name": "Python åŸç”Ÿè¿´åœˆæ¨¡å¼",
                "frequency": loop_count,
                "priority_score": loop_count * 5,
                "current_complexity": "O(n) Python è§£é‡‹å™¨é–‹éŠ·",
                "target_complexity": "O(n) C é€Ÿåº¦",
                "description": f"ç™¼ç¾ {loop_count} å€‹ for è¿´åœˆï¼Œå…¶ä¸­ {range_calls} å€‹ä½¿ç”¨ range()ï¼Œå¯èƒ½å¯ä»¥å‘é‡åŒ–åŠ é€Ÿ",
                "suggestions": [
                    "ä½¿ç”¨ NumPy å‘é‡åŒ–æ“ä½œæ›¿ä»£æ•¸å€¼è¨ˆç®—è¿´åœˆ",
                    "ä½¿ç”¨åˆ—è¡¨æ¨å°å¼æ›¿ä»£ç°¡å–®è¿´åœˆ",
                    "ä½¿ç”¨å…§å»ºå‡½æ•¸ (map, filter, sum) åŠ é€Ÿ"
                ],
                "blueprint": "vectorization_converter.md",
                "example_code": """
# âŒ Python è¿´åœˆ
result = []
for x in data:
    result.append(x ** 2)

# âœ… å‘é‡åŒ–æ“ä½œ
import numpy as np
result = np.array(data) ** 2
"""
            })
        
        # 3. CONFIG_LOAD æ¨¡å¼åˆ†æ - é‡è¤‡è¼‰å…¥æª”æ¡ˆ
        io_operations = {
            "open": function_calls.get("open", 0),
            "load": function_calls.get("load", 0),
        }
        
        # æª¢æŸ¥ JSON ç›¸é—œ imports
        json_usage = 0
        for import_stmt in self.frequency_data.get("popular_imports", {}):
            if "json" in import_stmt.lower():
                json_usage += self.frequency_data["popular_imports"][import_stmt]
        
        config_total = sum(io_operations.values()) + json_usage
        
        if config_total > 10:
            patterns.append({
                "pattern": "CONFIG_LOAD",
                "name": "é‡è¤‡æª”æ¡ˆè¼‰å…¥æ¨¡å¼",
                "frequency": config_total,
                "priority_score": config_total * 8,
                "current_complexity": "O(IO) é‡è¤‡ç£ç¢Ÿè®€å–",
                "target_complexity": "O(1) è¨˜æ†¶é«”å¿«å–",
                "description": f"ç™¼ç¾ {config_total} æ¬¡æª”æ¡ˆè¼‰å…¥æ“ä½œ (open: {io_operations['open']}, load: {io_operations['load']}, json: {json_usage})ï¼Œå¯èƒ½é‡è¤‡è¼‰å…¥è¨­å®šæª”",
                "suggestions": [
                    "ä½¿ç”¨ @lru_cache å¿«å–è¼‰å…¥çµæœ",
                    "å»ºç«‹å…¨åŸŸè¨­å®šç®¡ç†å™¨",
                    "é è¼‰å…¥å¸¸ç”¨è¨­å®šæª”åˆ°è¨˜æ†¶é«”"
                ],
                "blueprint": "config_cache.md",
                "example_code": """
# âŒ é‡è¤‡è¼‰å…¥
def get_config():
    with open('config.json') as f:
        return json.load(f)

# âœ… å¿«å–è¼‰å…¥
from functools import lru_cache

@lru_cache(maxsize=1)
def get_config():
    with open('config.json') as f:
        return json.load(f)
"""
            })
        
        # 4. HIGH_FREQUENCY_CALLS æ¨¡å¼ - é«˜é »ä½æ•ˆèª¿ç”¨
        high_freq_inefficient = []
        inefficient_patterns = {
            "print": ("I/O é˜»å¡", "æ”¹ç”¨ logging æ¨¡çµ„"),
            "len": ("é‡è¤‡è¨ˆç®—", "å¿«å–é•·åº¦å€¼"),
            "append": ("è¨˜æ†¶é«”é‡åˆ†é…", "ä½¿ç”¨ extend() æˆ–é åˆ†é…"),
            "get": ("å­—å…¸æŸ¥æ‰¾", "ä½¿ç”¨ defaultdict æˆ– setdefault"),
            "str": ("å­—ä¸²è½‰æ›", "æ¸›å°‘ä¸å¿…è¦çš„è½‰æ›"),
        }
        
        for func_name, (problem, solution) in inefficient_patterns.items():
            count = function_calls.get(func_name, 0)
            if count > 100:  # é«˜é »èª¿ç”¨é–¾å€¼
                high_freq_inefficient.append({
                    "func": func_name,
                    "count": count,
                    "problem": problem,
                    "solution": solution
                })
        
        if high_freq_inefficient:
            total_calls = sum(item["count"] for item in high_freq_inefficient)
            patterns.append({
                "pattern": "HIGH_FREQ_CALLS",
                "name": "é«˜é »ä½æ•ˆå‡½æ•¸èª¿ç”¨",
                "frequency": total_calls,
                "priority_score": total_calls * 3,
                "current_complexity": "ç´¯ç©æ•ˆèƒ½æå¤±",
                "target_complexity": "å„ªåŒ–å¯¦ä½œ",
                "description": f"ç™¼ç¾ {len(high_freq_inefficient)} ç¨®é«˜é »ä½æ•ˆèª¿ç”¨ï¼Œç¸½è¨ˆ {total_calls} æ¬¡",
                "details": high_freq_inefficient,
                "suggestions": [
                    "å°‡ print() æ›¿æ›ç‚º logging (é¿å… I/O é˜»å¡)",
                    "å¿«å– len() çµæœæˆ–ä½¿ç”¨è¨ˆæ•¸å™¨",
                    "æ‰¹é‡æ“ä½œæ›¿ä»£é »ç¹ append()",
                    "ä½¿ç”¨ defaultdict æ¸›å°‘ get() èª¿ç”¨"
                ],
                "blueprint": "frequency_optimization.md"
            })
        
        # æŒ‰å„ªå…ˆç´šåˆ†æ•¸æ’åº
        patterns.sort(key=lambda x: x["priority_score"], reverse=True)
        return patterns
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå„ªåŒ–å ±å‘Š"""
        patterns = self.analyze_code_patterns()
        
        if not patterns:
            return "# ğŸ¤·â€â™‚ï¸ æœªç™¼ç¾æ˜é¡¯çš„å„ªåŒ–æ©Ÿæœƒ\n\næ‚¨çš„ç¨‹å¼ç¢¼çœ‹èµ·ä¾†å·²ç¶“ç›¸ç•¶å„ªåŒ–äº†ï¼"
        
        report = f"""# ğŸš€ TurboCode Kit ç¨‹å¼ç¢¼å„ªåŒ–åˆ†æå ±å‘Š

## ğŸ“Š åˆ†ææ‘˜è¦

**åˆ†ææ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**ç¸½æª”æ¡ˆæ•¸**: {(self.frequency_data.get('total_files', 'N/A') if self.frequency_data else 'N/A')}  
**ç™¼ç¾æ¨¡å¼**: {len(patterns)} å€‹å¯å„ªåŒ–æ¨¡å¼  

---

## ğŸ¯ å„ªåŒ–å„ªå…ˆç´šæ¸…å–® (æŒ‰é »ç‡æ’åº)

| æ’å | æ¨¡å¼é¡å‹ | ç™¼ç¾é »ç‡ | å½±éŸ¿ç¨‹åº¦ | å„ªåŒ–ç›®æ¨™ | è—åœ–ç¯„æœ¬ |
|------|----------|----------|----------|----------|----------|
"""
        
        # å„ªå…ˆç´šè¡¨æ ¼
        for i, pattern in enumerate(patterns, 1):
            impact = "ğŸš¨ é«˜" if pattern["priority_score"] > 500 else "âš ï¸ ä¸­" if pattern["priority_score"] > 100 else "ğŸ’¡ ä½"
            report += f"| **{i}** | **{pattern['pattern']}** | {pattern['frequency']} æ¬¡ | {impact} | {pattern['current_complexity']} â†’ {pattern['target_complexity']} | `{pattern.get('blueprint', 'N/A')}` |\n"
        
        report += "\n---\n\n## ğŸ“‹ è©³ç´°å„ªåŒ–æŒ‡å—\n\n"
        
        # è©³ç´°èªªæ˜æ¯å€‹æ¨¡å¼
        for i, pattern in enumerate(patterns, 1):
            report += f"### {i}. {pattern['name']}\n\n"
            report += f"**ğŸ” æ¨¡å¼è­˜åˆ¥**: `{pattern['pattern']}`  \n"
            report += f"**ğŸ“ˆ ç™¼ç¾é »ç‡**: {pattern['frequency']} æ¬¡  \n"
            report += f"**âš¡ å„ªåŒ–æ½›åŠ›**: {pattern['current_complexity']} â†’ {pattern['target_complexity']}  \n"
            report += f"**ğŸ“ å•é¡Œæè¿°**: {pattern['description']}  \n\n"
            
            report += "**ğŸ› ï¸ å„ªåŒ–å»ºè­°**:\n"
            for suggestion in pattern["suggestions"]:
                report += f"- {suggestion}\n"
            
            if pattern.get("example_code"):
                report += f"\n**ğŸ’¡ ç¨‹å¼ç¢¼ç¯„ä¾‹**:\n```python{pattern['example_code']}\n```\n"
            
            if pattern.get("blueprint"):
                report += f"\n**ğŸ“– åƒè€ƒç¯„æœ¬**: `optimization_blueprints/{pattern['blueprint']}`\n"
            
            # ç‰¹æ®Šè™•ç†é«˜é »èª¿ç”¨è©³æƒ…
            if pattern["pattern"] == "HIGH_FREQ_CALLS" and pattern.get("details"):
                report += "\n**ğŸ“Š è©³ç´°èª¿ç”¨çµ±è¨ˆ**:\n"
                for detail in pattern["details"]:
                    report += f"- `{detail['func']}()`: {detail['count']} æ¬¡èª¿ç”¨ - {detail['problem']} â†’ {detail['solution']}\n"
            
            report += "\n" + "="*50 + "\n\n"
        
        # ä½¿ç”¨æŒ‡å—
        report += """## ğŸ¯ åŸ·è¡Œå„ªåŒ–çš„æ­¥é©Ÿ

### 1. é¸æ“‡ç›®æ¨™ ğŸª
**å¾ä¸Šæ–¹æ¸…å–®é¸æ“‡æ’åç¬¬ä¸€çš„æ¨¡å¼é–‹å§‹å„ªåŒ–**

### 2. æŸ¥çœ‹ç¯„æœ¬ ğŸ“š
```bash
# åƒè€ƒå°æ‡‰çš„å„ªåŒ–è—åœ–
code optimization_blueprints/lookup_accelerator.md
```

### 3. AI å”ä½œå„ªåŒ– ğŸ¤–
**å‘ Copilot ä¸‹é”æŒ‡ä»¤**:
```
è«‹åƒè€ƒ optimization_blueprints/lookup_accelerator.md ç¯„æœ¬ï¼Œ
å°‡æˆ‘ç¨‹å¼ç¢¼ä¸­çš„ LIST_LOOKUP æ¨¡å¼å„ªåŒ–ç‚º O(1) æŸ¥æ‰¾ã€‚
è«‹æ‰¾å‡ºæ‰€æœ‰ä½¿ç”¨ index()ã€count()ã€remove() çš„åœ°æ–¹ä¸¦å„ªåŒ–ã€‚
```

### 4. æ•ˆèƒ½æ¸¬è©¦ ğŸ§ª
```python
# ä½¿ç”¨å…§å»ºå·¥å…·æ¸¬è©¦
import time
from turbo_utils import quick_optimization_demo
quick_optimization_demo()
```

### 5. è¨˜éŒ„æˆæœ ğŸ“
- æ¸¬é‡å„ªåŒ–å‰å¾Œçš„åŸ·è¡Œæ™‚é–“
- è¨˜éŒ„åŠ é€Ÿå€ç‡ (ä¾‹å¦‚: 150ms â†’ 0.5ms = 300x åŠ é€Ÿ)
- æ·»åŠ  `# TCK Optimized` è¨»é‡‹æ¨™è¨˜

### 6. é‡è¤‡æµç¨‹ ğŸ”„
**å®Œæˆç¬¬ä¸€å€‹æ¨¡å¼å¾Œï¼Œé‡æ–°åŸ·è¡Œåˆ†æé¸æ“‡ä¸‹ä¸€å€‹ç›®æ¨™**

---

## ğŸ“ˆ é æœŸæˆæ•ˆ

"""
        
        # é æœŸæˆæ•ˆçµ±è¨ˆ
        total_optimizations = len(patterns)
        high_impact = len([p for p in patterns if p["priority_score"] > 500])
        
        report += f"- **å¯å„ªåŒ–é …ç›®**: {total_optimizations} å€‹æ¨¡å¼\n"
        report += f"- **é«˜å½±éŸ¿é …ç›®**: {high_impact} å€‹ (é æœŸåŠ é€Ÿ >10x)\n"
        report += "- **é ä¼°ç¸½æå‡**: 20-50% ç¨‹å¼ç¢¼åŸ·è¡Œæ•ˆèƒ½\n\n"
        
        report += "---\n*ç”± TurboCode Kit (TCK) v2.0 ç”Ÿæˆ*"
        
        return report
    
    def run(self) -> bool:
        """åŸ·è¡Œå ±å‘Šç”Ÿæˆ"""
        print("ğŸš€ TurboCode Kit å„ªåŒ–åˆ†æå ±å‘Šç”Ÿæˆä¸­...")
        
        if not self.load_analysis_data():
            print("âŒ ç„¡æ³•è¼‰å…¥åˆ†ææ•¸æ“š")
            return False
        
        report_content = self.generate_report()
        
        # ä¿å­˜ Markdown å ±å‘Š
        report_file = self.output_dir / "optimization_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… å„ªåŒ–å ±å‘Šå·²ç”Ÿæˆ: {report_file}")
        
        # é¡¯ç¤ºæ‘˜è¦
        patterns = self.analyze_code_patterns()
        if patterns:
            print(f"\nğŸ“Š ç™¼ç¾ {len(patterns)} å€‹å¯å„ªåŒ–æ¨¡å¼:")
            for i, pattern in enumerate(patterns[:3], 1):
                print(f"  {i}. {pattern['pattern']}: {pattern['frequency']} æ¬¡")
            if len(patterns) > 3:
                print(f"  ... é‚„æœ‰ {len(patterns) - 3} å€‹æ¨¡å¼")
        
        return True


def main():
    generator = OptimizationReportGenerator()
    generator.run()


if __name__ == "__main__":
    main()